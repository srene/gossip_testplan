{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a46c2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sergi/workspace/gossip_test/clecdbalo7jb9ut0vri0.tgz\n",
      "/home/sergi/seal/tmpo2/pubsub-tg-archive-6_z0612r\n",
      "/home/sergi/seal/tmpo2/pubsub-tg-archive-6_z0612r\n",
      "/home/sergi/seal/tmpo2/pubsub-tg-archive-6_z0612r\n",
      "running tracestat on /home/sergi/workspace/gossip_test/clecdbalo7jb9ut0vri0/raw-data/full-trace.bin.gz\n",
      "converting data to pandas format...\n",
      "converting latency cdf to pandas...\n",
      "writing cdf pandas data to /home/sergi/workspace/gossip_test/clecdbalo7jb9ut0vri0/pandas/cdf.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/sergi/workspace/gossip_test/clecdbalo7jb9ut0vri0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from glob import glob\n",
    "import gzip\n",
    "import contextlib\n",
    "import json\n",
    "import re\n",
    "import zipfile\n",
    "import tarfile\n",
    "import tempfile\n",
    "import os\n",
    "import pathlib\n",
    "import subprocess\n",
    "import notebook_helper\n",
    "\n",
    "# depending on which test runner was used, the collection archive may be either a zip (local docker & exec runner),\n",
    "# or a tar.gz file (k8s). Unfortunately, the zipfile and tarfile modules are different species of waterfowl,\n",
    "# so we duck typing doesn't help. So this method extracts whichever one we have to a temp directory and\n",
    "# returns the path to the temp dir.\n",
    "# use as a context manager, so the temp dir gets deleted when we're done:\n",
    "#   with open_archive(archive_path) as a:\n",
    "#     files = glob(a + '/**/tracer-output')\n",
    "@contextlib.contextmanager\n",
    "def open_archive(archive_path):\n",
    "    # zipfile and tarfile both have an extractall method, at least\n",
    "    #print(archive_path)\n",
    "    if zipfile.is_zipfile(archive_path):\n",
    "        z = zipfile.ZipFile(archive_path)\n",
    "    else:\n",
    "        z = tarfile.open(archive_path, 'r:gz')\n",
    "\n",
    "    #print(z)\n",
    "    with tempfile.TemporaryDirectory(prefix='pubsub-tg-archive-') as d:\n",
    "        print(d)\n",
    "        z.extractall(path=d)\n",
    "        yield d\n",
    "   \n",
    "def concat_files(names, outfile):\n",
    "    for name in names:\n",
    "        with open(name, 'rb') as f:\n",
    "            outfile.write(f.read())\n",
    "\n",
    "def mkdirp(dirpath):\n",
    "    pathlib.Path(dirpath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PEER_INFO_PATTERN = re.compile(\n",
    "    r'Host peer ID: ([0-9a-zA-Z]+), seq (\\d+)')\n",
    "\n",
    "\n",
    "def extract_peer_info(run_out):\n",
    "    infos = []\n",
    "    with open(run_out, 'rt') as f:\n",
    "        for line in f.readlines():\n",
    "            m = PEER_INFO_PATTERN.search(line)\n",
    "            if m:\n",
    "                pid = m.group(1)\n",
    "                seq = int(m.group(2))\n",
    "                node_type = m.group(3)\n",
    "                node_type_seq = int(m.group(4))\n",
    "                node_index = int(m.group(5))\n",
    "                node_index_bound = int(m.group(6))\n",
    "                infos.append(\n",
    "                    {'peer_id': pid,\n",
    "                     'seq': seq})\n",
    "    if len(infos) == 0:\n",
    "        print('warning: no peer info found in {}'.format(run_out))\n",
    "    return infos\n",
    "\n",
    "def extract_timing_info(run_out, node_type):\n",
    "    times = dict(t_warm=0, t_connect=0, t_run=0, t_cool=0, t_complete=0)\n",
    "\n",
    "    with open(run_out, 'rt') as f:\n",
    "        for line in f.readlines():\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except BaseException as err:\n",
    "                print(\"error parsing run output: \", err)\n",
    "                continue\n",
    "            if 'ts' not in obj or 'event' not in obj or obj['event'].get('type', '') != 'message':\n",
    "                continue\n",
    "            msg = obj['event']['message']\n",
    "            ts = obj['ts']\n",
    "            if re.match(r'connecting to peers.*', msg):\n",
    "                times['t_connect'] = ts\n",
    "                continue\n",
    "\n",
    "            # the rest of the times are only logged by honest peers\n",
    "            if node_type != 'honest':\n",
    "                continue\n",
    "            if re.match(r'Wait for .* warmup time', msg):\n",
    "                times['t_warm'] = ts\n",
    "                continue\n",
    "            if re.match(r'Wait for .* run time', msg):\n",
    "                times['t_run'] = ts\n",
    "                continue\n",
    "            if re.match(r'Run time complete, cooling down.*', msg):\n",
    "                times['t_cool'] = ts\n",
    "                continue\n",
    "            if msg == 'Cool down complete':\n",
    "                times['t_complete'] = ts\n",
    "                continue\n",
    "            \n",
    "def extract_peer_and_timing_info(run_out_files):\n",
    "    entries = []\n",
    "    for filename in run_out_files:\n",
    "        infos = extract_peer_info(filename)\n",
    "        print(infos)\n",
    "        if infos is None or len(infos) == 0:\n",
    "            continue\n",
    "\n",
    "        # FIXME: we only get the timing info for the first peer in the container\n",
    "        # unfortunately, getting the times for individual peers requires code changes\n",
    "        times = extract_timing_info(filename, infos[0].get('type', 'unknown'))\n",
    "        for info in infos:\n",
    "            info.update(times)\n",
    "            entries.append(info)\n",
    "    return entries\n",
    "\n",
    "# sugar around recursive glob search\n",
    "def find_files(dirname, filename_glob):\n",
    "    path = '{}/**/{}'.format(dirname, filename_glob)\n",
    "    return glob(path, recursive=True)\n",
    "\n",
    "def aggregate_output(output_zip_path, out_dir):\n",
    "    topology = dict()\n",
    "\n",
    "    print(output_zip_path)\n",
    "    with open_archive(output_zip_path) as archive:\n",
    "        print(archive)\n",
    "        tracefiles = find_files(archive, 'tracer-output*')\n",
    "        names = [f for f in tracefiles if 'full' in f]\n",
    "        if len(names) > 0:\n",
    "            with gzip.open(os.path.join(out_dir, 'full-trace.bin.gz'), 'wb') as gz:\n",
    "                concat_files(names, gz)\n",
    "\n",
    "        names = [f for f in tracefiles if 'filtered' in f]\n",
    "        if len(names) > 0:\n",
    "            with gzip.open(os.path.join(out_dir, 'filtered-trace.bin.gz'), 'wb') as gz:\n",
    "                concat_files(names, gz)\n",
    "\n",
    "        print(archive)\n",
    "        # get peer id -> seq mapping & timing info from run.out files\n",
    "        #names = find_files(archive, 'run.out')\n",
    "        #info = extract_peer_and_timing_info(names)\n",
    "        #dest = os.path.join(out_dir, 'peer-info.json')\n",
    "        #with open(dest, 'wt') as f:\n",
    "        #    json.dump(info, f)\n",
    "\n",
    "def extract_test_outputs(test_output_zip_path, output_dir=None):\n",
    "    if output_dir is None or output_dir == '':\n",
    "        output_dir = os.path.join(os.path.dirname(test_output_zip_path), 'analysis')\n",
    "\n",
    "    raw_output_dir = os.path.join(output_dir, 'raw-data')\n",
    "    mkdirp(raw_output_dir)\n",
    "    aggregate_output(test_output_zip_path, raw_output_dir)\n",
    "    run_tracestat(raw_output_dir)\n",
    "\n",
    "    #if convert_to_pandas:\n",
    "    print('converting data to pandas format...')\n",
    "    pandas_dir = os.path.join(output_dir, 'pandas')\n",
    "\n",
    "    notebook_helper.to_panda(raw_output_dir, pandas_dir)\n",
    "    #if prep_notebook:\n",
    "    #    prepare_analysis_notebook(analysis_dir=output_dir)\n",
    "    return output_dir\n",
    "\n",
    "def run_tracestat(tracer_output_dir):\n",
    "    full = os.path.join(tracer_output_dir, 'full-trace.bin.gz')\n",
    "    filtered = os.path.join(tracer_output_dir, 'filtered-trace.bin.gz')\n",
    "    if os.path.exists(full):\n",
    "        tracer_output = full\n",
    "    elif os.path.exists(filtered):\n",
    "        tracer_output = filtered\n",
    "    else:\n",
    "        print('no event tracer output found, skipping tracestat')\n",
    "        return\n",
    "\n",
    "    print('running tracestat on {}'.format(tracer_output))\n",
    "    try:\n",
    "        cmd = ['tracestat', '-cdf', tracer_output]\n",
    "        p = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "    except BaseException as err:\n",
    "        print('error calling tracestat: ', err)\n",
    "        return\n",
    "\n",
    "    # split output into summary and latency CDF\n",
    "    [summary, cdf] = p.stdout.split('=== Propagation Delay CDF (ms) ===')\n",
    "\n",
    "    with open(os.path.join(tracer_output_dir, 'tracestat-summary.txt'), 'w', encoding='utf8') as f:\n",
    "        f.write(summary)\n",
    "    with open(os.path.join(tracer_output_dir, 'tracestat-cdf.txt'), 'w', encoding='utf8') as f:\n",
    "        f.write(cdf)\n",
    "\n",
    "    #print(cdf)\n",
    "\n",
    "\n",
    "extract_test_outputs('/home/sergi/workspace/gossip_test/clecdbalo7jb9ut0vri0.tgz','/home/sergi/workspace/gossip_test/clecdbalo7jb9ut0vri0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f1c2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483bef9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
